\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish, mexico]{babel}
\usepackage{listings}
\usepackage{breakcites}
\usepackage{dsfont}
\usepackage{hyperref}
\usepackage{amssymb,amsthm,amsmath,latexsym}
\usepackage[margin=1.5cm]{geometry}
\usepackage{natbib}
%\bibliographystyle{stylename}
%\usepackage{fancyhdr}
%\pagestyle{fancy}
\theoremstyle{plain}
\newtheorem{teo}{Teorema}
\newtheorem{prop}[teo]{Proposición}
\newtheorem{defi}[teo]{Definición}
\newtheorem{obs}[teo]{Observación}
\newtheorem{lem}[teo]{Lema}
\newtheorem{cor}[teo]{Corolario}
\usepackage[pdftex]{color,graphicx}
\usepackage{tikz}
\usetikzlibrary{calc}
%\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\title{Problemas de Decisión bajo Incertidumbre: el caso de estructura causal.}
\author{Mauricio Gonzalez Soto}
\begin{document}
%\nocite{*}
\maketitle
\section{Introducción}
En múltiples ocasiones y contextos diversos los seres humanos nos vemos forzados a tomar decisiones cuyas consecuencias son inciertas (\cite{danks2014unifying}). A lo más, podemos contar con estimaciones sobre lo probable que es la ocurrencia de algún evento incierto.\\
\\
La Teoría de la Decisión bajo Incertidumbre, desarrollada en los trabajos de \cite{von1944theory}, \cite{definetti1930}, \cite{definetti1937}, \cite{savage1954the}, \cite{bernardo2000bayesian}, define un criterio formal de elección, el cual consiste en la maximización de la utilidad esperada.\\
\\
Para calcular la utilidad esperada, es necesario contar con estimaciones de la probabilidad de ocurrencia de ciertos eventos inciertos, la interpretación de la probabilidad es un tema por sí solo interesante, y en este contexto existen dos variantes: en el contexto del Teorema de Von Neuman-Morgenstern, si un tomador de decisiones conoce las probabilidades de los eventos, entonces existe una función de utilidad tal que la relación de preferencias del agente es equivalente con la utilidad esperada respecto a esta función y las probabilidades conocidas; por otro lado, el Teorema de DeFinnetti supone conocida la utilidad para el agente y el resultado garantiza la existencia de una medida de probabilidad tal que la relación de preferencias es equivalente a maximizar la utilidad respecto a esta medida. Finalmente, el Teorema de Savage supone una serie de axiomas de coherencia que debe de cumplir una relación de preferencias y con ellos muestra la existencia de una función de utilidad y de una medida de probabilidad tal que la relación de preferencias es equivalente a la maximización de la utilidad esperada. Existen otros criterios de optimalidad cuando los axiomas de Savage son cuestionados; por ejemplo, la utilidad maxmin, o la utilidad esperada de Choquet (\cite{gilboa2009decision}).\\
\\
En diversas ocasiones, un tomador de decisiones no tiene a su alcance todos los parámetros (probabilidades de los eventos), pero puede intentar \textit{aprenderlos} del mismo entorno, sobre esto ya se ha dicho mucho en el área de Aprendizaje por Refuerzo (\cite{sutton1998reinforcement}). Una de las grandes limitaciones de estos métodos es que aprenden formas de actuar que son puramente reactivas; es decir, no capturan, ni intentan, la estructura del ambiente. Un caso particular de esta estructura se da en el caso en el cual el tomador de decisiones sabe, o cree, que en el ambiente en el cual se llevan a cabo sus decisiones existen relaciones causa-efecto.
\section{Motivación}
Las relaciones causa-efecto\footnote{Entendiendo causalidad como la define \cite{spirtes2000causation}; es decir, como una relación transitiva, irreflexiva y antisimétrica entre eventos, de manera que sucede uno y esto causa que otro evento sea producido.} son de gran utilidad en problemas de decisión, pues conociendo los \textit{efectos} de las posibles decisiones a tomar, el agente puede planear mejor sus acciones (\cite{hagmayer2013repeated},\cite{pearlwhy}). De hecho, se ha estudiado el caso de agentes que son racionales en un entorno causal (\cite{board2006equivalence}). En particular, en el área de la Economía conocida como Economía Conductual (Behavioral Economics) es muy importante dotar agentes que tienen un comportamiento incoherente con incentivos para recuperar esa coherencia, lo cual se puede hacer si se conocen los \textit{efectos} de sus acciones (\cite{kleinberg2014time}). Además, la información causal por sí sola nos ayuda a los seres humanos a tomar decisiones, pues resulta que los seres humanos utilizan información causal al tomar decisiones; además, modifican la información causal previa que tenían del ambiente conforme interactúan con este (\cite{hagmayer2013repeated}). Por otro lado, \cite{lattimoreNIPS2016} muestran que contar con un modelo causal permite tomar decisiones de modo que se alcance cierto objetivo.\\
\\
Han existido diversos intentos de formalizar una Teoría de Decisión que incorpore información causal, como han sido los trabajos de \cite{joyce1999foundations}, \cite{board2006equivalence}, \cite{joyce2012regret}, \cite{ahmed2012push}, \cite{rottman2014reasoning}, \cite{soares2015toward}, \cite{stalnaker2016knowledge}, los cuales hacen uso del “razonamiento contrafactual” para proponer una manera de tomar decisiones a la luz de “lo que hubiera pasado si...”, pero estos trabajos tienen ciertas limitaciones filosóficas y conceptuales, pues ignoran el caso en el cual las acciones de un tomador de decisiones están correlacionadas (pero no causalmente conectadas) con algunas partes del ambiente, además de la dificultad que implica la construcción de un modelo causal. \\
\\
Teoría de Juegos (\cite{osborne1994course}) es un área de las matemáticas que los economistas y otros científicos sociales utilizan para modelar situaciones de interacción estratégica; es decir, problemas de decisión en los cuales importa no solo las acciones y preferencias de un sólo agente sino las de otros. En particular, en esta área existen los llamados \textit{juegos Bayesianos} en los cuales cada jugador tiene creencias \textit{a priori} sobre algunos aspectos del ambiente (en las aplicaciones de economía estas creencias suelen versar sobre las recompensas o sobre las estrategias de otros jugadores). En general, los juegos Bayesianos pertenecen a una clase de juegos llamados juegos estratégicos.\\
\\
La clase de juegos necesaria para modelar un proceso de decisiones secuenciales bajo incertidumbre y con información incompleta se llaman \textit{Juegos Estocásticos}, que fueron introducidos por \cite{shapley1953stochastic} y generalizan los Procesos de Decisión Markovianos (MDP), así como los juegos repetido, pues un MDP es simplemente un juego estocástico con un solo jugador mientras que un juego repetido es un juego estocástico de una sola etapa (\cite{shoham2008multiagent}).\\
\\
A diferencia de lo que sucede en Aprendizaje por Refuerzo (RL por sus siglas en inglés), en donde el agente lleva a cabo una acción y observa una señal de recompensa del ambiente, lo que se propone es a observar una \textit{jugada} de la Naturaleza; es decir, toda una acción y no sólo una cuantificación de lo devuelto por el entorno. Diseñar una señal de recompensa es un problema difícil en general (\cite{sutton1998reinforcement},\cite{dewey2014reinforcement}, \cite{DRLnotwork}). Además, se pretende operar a la luz de un modelo causal verdadero que rige lo que ocurre en el ambiente; pudiera ocurrir que una señal de recompensa sea construída de modo que oculte estas relaciones al agente, por eso se opta por observar lo que ocurre afuera como jugadas y dejar al agente escoger entre sus acciones y las consecuencias de éstas.
\section{Justificación}
El trabajo de \cite{lattimoreNIPS2016} muestra que conocer información causal sobre cierto entorno ayuda a tomar decisiones de modo que se logre un objetivo externo; en particular, ellos consideran el caso en el cual un tomador de decisiones quiere maximizar cierta variable de recompensa y las acciones que tiene a su disposición el agente están relacionadas de manera causal con la variable recompensa. Se sabe que los seres humanos conciben sus acciones en el mundo como \textit{intervenciones} sobre este (\cite{hagmayer2009decision}). De manera similar, el modelo de \cite{lattimoreNIPS2016} concibe las acciones disponibles al agente como posibles \textit{intervenciones} en el entorno; la dinámica que ellos proponen consiste en que posterior a cada intervención, el agente observa el valor de la recompensa así como la realización de las otras variables que no fueron intervenidas; en esto consiste una \textit{ronda}. En la siguiente ronda, el entorno vuelve a su estado inicial y el agente selecciona otra posible intervención y vuelve a observar estas variables. Esta dinámica de rondas repetidas lleva a los autores a modelar el problema como escoger brazos en una máquina tragamonedas (bandits en la literatura) y observar el pago. El algoritmo que desarrollan aprende la \textit{intervención óptima} después de un número $T$ de rondas fijado por el agente.\\
\\
Este trabajo muestra cómo a la luz de un modelo causal se pueden tomar decisiones utilizando esta información con el objetivo de maximizar cierta variable. La limitación que tiene este trabajo es suponer conocido de antemano el modelo causal, pero para modelar un escenario más realista es necesario suponer no conocido el modelo causal e intentar aprender sobre éste a partir de las interacciones mismas con el ambiente; de hecho es, en parte, como operamos los seres humanos (\cite{hagmayer2013repeated}). La importancia del razonamiento causal para el desarrollo de agentes inteligentes está detallada y justificada en \cite{lake2017building}.
\section{Problema de investigación}
Adqusición y uso de información causal en problemas de toma de decisiónes secuenciales bajo incertidumbre.
\section{Planteamiento del Problema}
Supondremos que se conoce de antemano cuando un ambiente está regido por un modelo causal, y suponemos que este es desconocido, pero fijo.\\
\\
Un problema de decisión bajo incertidumbre (de una etapa) consiste en un conjunto de acciones, un conjunto de consecuencias y un conjunto de \textit{eventos inciertos}; la interpretación estándar es que el agente escogerá una de estas acciones, luego ocurrirá uno de estos eventos inciertos y será esto lo que determine la consecuencia. Suponer que un modelo causal exista y opere sobre este ambiente implica que éste controle la relación entre los eventos inciertos y las consecuencias de éste, lo cual queda codificado en probabilidades; de este modo, si se conoce el modelo causal, se conocen las probabilidades de ocurrencia de las consecuencias dada la acción escogida y el evento incierto. De esta manera, se puede determinar la acción óptima (o serie de acciones) mediante la maximización de la utilidad esperada, pues este es el único criterio de solución que es coherente con los axiomas de decisión de \cite{savage1954the}.\\
\\
En cambio, cuando no se conoce el modelo causal, no se puede utilizar la utilidad esperada para encontrar el camino a seguir. Entonces, se podría intentar aprender los parámetros a partir de la información que provee el ambiente posterior a cada interacción con este. Sabemos que un problema de decisión bajo incertidumbre puede resolverse con algunas de las técnicas ya conocidas en el área de Aprendizaje por Refuerzo (\cite{sutton1998reinforcement}), resulta además que una política óptima aprendida con estas técnicas alcanza la MUE (\cite{webb2007game}). Lo que estas técnicas no toman en cuenta es cuando el agente sabe que su entorno tiene cierta estructura particular, y se desea utilizar esta información para aprender los parámetros del modelo y tomar decisiones de manera correcta.\\
\\
Para esto, queremos dotar al agente con una manera de considerar \textit{creencias} sobre la estructura de su entorno las cuales se irán modificando conforme el agente interactue con éste. Para modelar la interacción, a diferencia de lo usual en aprendizaje por refuerzo en donde el agente está “solo con su entorno”, nosotros vamos a asumir que el agente está interactuando con otro ente abstracto (llamémosle Naturaleza), y esta interacción la vamos a modelar como un \textit{juego}.\\
\\
En resumen, el modelo consiste en traducir un problema de toma de decisiones bajo incertidumbre en un juego Bayesiano entre el tomador de decisiones y la Naturaleza donde esta última va a muestrear sus acciones a partir del modelo causal que opera en el entorno y que establece las relaciones causales entre variables así como entre acciones y variables. Queremos que a lo largo de las jugadas (o de repeticiones de los juegos) el jugador vaya actualizando sus creencias causales y descubriendo ese modelo causal; es decir, se necesita que las creencias actualizadas del jugador converjan al verdadero modelo. Además, utilizando el concepto de \textit{estrategias mixtas} el jugador puede tomar ciertas acciones de manera aleatoria, lo que introduce el concepto de \textit{exploración} proveniente del área de RL. Lo que esperamos tener al final de un cierto número de rondas de aprendizaje es un \textit{diagrama de influencia causal}, que consistirá en la extensión al caso causal de los diagramas de influencia tradicionales.\\
\\
Un primer planteamiento sería considerar que las acciones de la naturaleza son completamente \textit{desinteresadas}; es decir, que la naturaleza no tiene ningún objetivo en particular. En \cite{eberhardt2008causal} el problema de descubrimiento causal es planteado también como un juego, en el cual la naturaleza escoge desde el inicio el modelo causal \textit{real} y el jugador debe escoger intervenciones a llevar a cabo con tal de descubrir el modelo causal. En este caso el objetivo es descubrir el modelo causal, no el aspecto de toma de decisiones.
\section{Trabajo Previo}
Existen trabajos que utilizan en conjunto inferencia causal junto con toma de decisiones; por ejemplo \cite{heckerman1995decision} argumenta que los trabajos usuales sobre causalidad no contienen primitivas suficientemente básicas, por lo que plantea el problema de inferencia causal como uno de toma de decisiones.\\
\\
Por otro lado, \cite{dawid2002influence} explica cómo plantear un problema de inferencia causal utilizando diagramas de influencia, los cuales son una extensión de las redes Bayesianas para incluir nodos de decisión, y los cuales pueden utilizarse para descubrir las acciones óptimas en un problema de decisión tradicional (sí, aquella serie de acciones que obtiene la máxima utilidad esperada). El interés del autor es utilizar la representación de diagramas de influencia para \textit{interrogar} el fenómeno. En nuestro caso, el objetivo es \textit{construir} este diagrama mediante un ciclo de decisión-observación.\\
\\
\cite{koller2003multi} utilizan diagramas de influencia para encontrar estrategias relevantes en juegos multi-agente, con lo cual descomponen un juego grande en varios juegos más chicos que se resuelven de manera secuencial.\\
\\
\cite{board2006equivalence} define la racionalidad causal en juegos, concepto que toma en cuenta lo que se espera que otros jugadores hagan; es decir, toma en cuenta que las acciones de un jugador puedan tener efectos en las estrategias de los otros jugadores. Resulta que este concepto es equivalente a la racionalidad bayesiana estándar bajo el supuesto de independencia causal.\\
\\
\cite{soares2015toward} compara, desde un punto de vista epistemológico, la toma de decisiones apoyada en evidencia versus el uso de uso de razonamiento contrafactual en la toma de decisiones, aunque conceptualmente esta última permite llevar a cabo razonamientos más complejos el problema que se presenta en la práctica es precisamente la construcción del modelo causal a partir del cual se van a tomar decisiones.\\
\\
Por otro lado, desde un punto de vista computacional, \cite{lattimoreNIPS2016} atacan el problema de toma de decisiones en entornos causales pero bajo un modelo causal conocido; en este modelo, las acciones a escoger son intervenciones posibles en el grafo causal y lo que se busca es maximizar cierta variable de recompensa que está influenciada directamente por el modelo causal. La optimalidad de su acción está determinada en términos del \textit{regret} mínimo, que es básicamente un valor esperado. Esta medida de optimalidad no está relacionada con ninguna función de utilidad asociada a un agente y esto restringe que el mismo problema se resuelva con distintos fines en mente. En este trabajo se asume que el modelo causal es conocido y plantean como trabajo futuro el caso en el cual se desconoce el modelo, que es precisamente el caso que se busca atacar aquí.\\
\\
Modelar problemas de decisión como un juego de manera que se vaya aprendiendo a realizar una tarea ha sido explorado previamente en \cite{werling2015job}, quienes modelan un problema de clasificación \textit{on-line} como un juego, pero en el cual las acciones del tomador de decisiones consisten en utilizar un oráculo para clasificar las observaciones iniciales. De manera similar, \cite{javdani2014near} utilizan teoría de la decisión Bayesiana para seleccionar experimentos que proporcionen la mayor información respecto a un fenómeno.\\
\\
\cite{larrouy2017mindreading} estudian la formación de creencias a partir de las acciones observadas y definen el concepto de \textit{mindreading}; es decir, poder adelantarse a las creencias que el otro jugador tomará en cuenta a la hora de tomar sus decisiones.\\
\\
La relación entre Teoría de Juegos, toma de decisiones e incorporación de información adicional (causal) parece muy clara, aunque no ha sido particularmente explotada. A lo más, los trabajos plantean el problema per se de inferencia causal \textit{como} un juego. Por ejemplo, \cite{heckerman1995decision}, \cite{eberhardt2008causal}  En nuestro caso, lo que se propone es jugar un juego para el cual existan relaciones causales de fondo y utilizar lo que se pueda aprender de estas.
\section{Objetivos}
Para llevar a cabo lo anterior se necesita desarrollar:
\begin{itemize}
\item Una forma de especificar creencias sobre estructura causal; esto puede ser mediante una distribución probabilista sobre un espacio de grafos. Podemos suponer que el número de variables es conocido de antemano, con lo cual podríamos limitarnos a trabajar sobre distribuciones de matrices de tamaño fijo. Si se permite que el número de variables sea arbitrario/desconocido, tendríamos que operar con modelos Bayesianos no paramétricos.
\item Un criterio de actualización de creencias causales que además debe cumplir la propiedad de que converge al verdadero modelo causal así como ser coherente con estudios de la psicología de la formación de creencias (\cite{larrouy2017mindreading}). Es importante mencionar que los juegos Bayesianos, en su definición estándar, proveen un mecanismo para la actualización general de creencias, pero se necesita una manera de actualizar creencias que haga uso de la estructura causal misma.
\item Un criterio de solución del problema: Si no es posible esperar hasta la convergencia del modelo, sí debemos garantizar que las decisiones tomadas con el modelo causal aprendido hasta cierta ronda aproximen la utilidad máxima esperada.
\item Una manera de construir un diagrama de influencia causal que además permita \textit{exportar} el conocimiento adquirido para problemas similares; de esta manera, ya sabríamos directamente cómo actuar conociendo el modelo causal.
\end{itemize}
\section{Ejemplo}
Supongamos que un paciente llega a un hospital debido a que tiene la enfermedad $A$ con probabilidad $p$ o la enfermedad $B$ con probabilidad $q$. El médico de guardia tiene a su alcance tres tratamientos posibles: cirugía, fármaco o nada. En caso de no hacer nada, el paciente morirá con una probabilidad $p_{dn}=0.8$ y sobrevivirá con una probabilidad $1-p_d$. Sin importar la enfermedad, el paciente puede morir durante la cirugía con probabilidad $p_{dc}=0.5$. De la misma manera, el medicamento producirá una reacción alérgica mortal con probabilidad $p_{df}=0.2$\\
\\
Si el paciente tenía la enfermedad $A$, y no muere de una reacción alérgica al fármaco, entonces el fármaco le curará con una probabilidad de $p_{sf}=0.9$. Si el paciente tenía la enfermedad $B$, entonces el fármaco no le curará y morirá.\\
\\
Por otro lado, si el paciente sobrevive a la cirugía, ésta le curará con una probabilidad de $0.5$ si el paciente tenía la enfermedad $A$. Si el paciente tenía la enfermedad $B$, entonces ésta lo curará con probabilidad de $0.6$. \qed
\\
\\
Entonces, en este ejemplo, tenemos que el juego consiste en el médico, y en la Naturaleza. Las acciones disponibles al médico son:
\[ A= \{ \textrm{fármaco},  \textrm{cirugía}, \textrm{nada} \}. \]
Por otro lado, las jugadas de la Naturaleza son: 
\[ A= \{ \textrm{A, B, vive, muere} \}. \] 
El juego va así:
\begin{itemize}
\item Primero, la naturaleza hace su jugada, lo cual determina qué enfermedad tenía el paciente. 
\item Después, el médico decide qué hacer. 
\item Posteriormente, la Naturaleza lanzará una moneda cargada que determinará si el paciente sobrevive. Notemos que, de manera latente, es un modelo causal el que determina que el fármaco no cura la enfermedad B, o que éste causa alergias, etc.
\end{itemize}
Sabemos que el médico fue a la escuela de medicina, de donde posee una gran cantidad de información (causal) a priori, pero puede que se esté enfrentando a una nueva enfermedad, es decir, no conoce realmente las probabilidades de muerte ni los casos en que el fármaco no actua.\\
\\
Lo que se desea es que a partir de este caso (juego), o de varios más, pueda actualizar su conocimiento causal para la siguiente ocasión en la que deba enfrentarse a  un problema similar.\\
\\
Notemos las similaridades que existen entre este ejemplo y el problema atacado por \cite{lattimoreNIPS2016}, quienes buscan escoger la \textit{mejor intervención} en un modelo causal dado con tal de maximizar cierta recompensa. En su modelo, un agente puede intervenir el modelo, y observar la recompensa y luego empezar desde cero; en nuestro caso, llega un paciente, el médico propone una acción, observa los efectos y procede con el siguiente paciente. El médico no conoce el modelo, que es la situación que \cite{lattimoreNIPS2016} dejan como trabajo futuro al final de su artículo. \\
\\
Para ser coherentes con el planteamiento de \cite{lattimoreNIPS2016} la actualización de creencias debe suceder al final de uno (o varios) juegos; además, el caso secuencial se atacará posteriormente.\\
\\
% Node styles
\tikzset{
% Two node styles for game trees: solid and hollow
solid node/.style={circle,draw,inner sep=1.5,fill=black},
hollow node/.style={circle,draw,inner sep=1.5}
}
\begin{tikzpicture}[scale=1.5,font=\footnotesize]
% Specify spacing for each level of the tree
\tikzstyle{level 1}=[level distance=15mm,sibling distance=35mm]
\tikzstyle{level 2}=[level distance=15mm,sibling distance=15mm]
% The Tree
\node(0)[solid node,label=above:{$N$}]{}
child{node(1)[solid node]{}
child{node[hollow node,label=below:{$(a,b)$}]{} edge from parent node[left]{$f$}}
child{node[hollow node,label=below:{$(c,d)$}]{} edge from parent node[right]{$c$}}
child{node[hollow node,label=below:{$(c,d)$}]{} edge from parent node[right]{$n$}}
edge from parent node[left,xshift=-3]{$A$}
}
child{node(2)[solid node]{}
child{node[hollow node,label=below:{$(e,f)$}]{} edge from parent node[left]{$f$}}
child{node[hollow node,label=below:{$(g,h)$}]{} edge from parent node[right]{$c$}}
child{node[hollow node,label=below:{$(c,d)$}]{} edge from parent node[right]{$n$}}
edge from parent node[right,xshift=3]{$B$}
};
% information set
\draw[dashed,rounded corners=10]($(1) + (-.2,.25)$)rectangle($(2) +(.2,-.25)$);
% specify mover at 2nd information set
\node at ($(1)!.5!(2)$) {$M$};
\end{tikzpicture}
\section{Metodología}
Para cumplir con los objetivos planteados antes, se propone:
\begin{itemize}
\item Consideramos un problema de decisión bajo incertidumbre que se desarrolla en un entorno regido por un modelo causal. En una primera etapa, consideramos que el número de variables que están contenidas en ese modelo es finito y conocido para el tomador de decisiones.
\item Para este caso finito, se debe encontrar una manera para incorporar conocimiento causal inicial, o previo, el cual debe ser coherente con lo que se conoce, o no, sobre el problema, además de ser coherente con la manera en la que los seres humanos formamos creencias (\cite{larrouy2017mindreading}).
\item Este conocimiento causal inicial debe ser expresado en términos de probabilidades y para esto se construirá un \textit{prior} que consiste en una distribución sobre un espacio de matrices. Recordemos que una matriz (que cumple ciertas características) define un grafo, por lo que tener de esta manera estaremos especificando las probabilidades que un agente asigna, de manera subjetiva, a distintos modelos causales. 
\item De acuerdo a las características del problema de decisión se planteará un juego de dos jugadores, uno de los cuales será el tomador de decisiones inicial, y el otro será un ente abstracto llamado Naturaleza que, suponemos, conoce el modelo causal y lleva a cabo sus jugadas a partir de lo dictado por éste. Los juegos sucederán de manera repetida para poder aprender de éste.
\item Definir un número de juegos de observación, dentro de estos juegos el tomador de decisiones no modificará sus creencias causales, aunque éstas lo obliguen a tener un desempeño no óptimo.
\item Definir una estrategia para el tomador de decisiones a partir del conocimiento causal que tenga hasta ese momento; una \textit{estrategia mixta} permitiría explorar el ambiente con tal de explorar el ambiente de manera amplia.
\item A partir de lo observado en la ronda de juegos de observación, se debe actualizar las creencias causales de manera que se reflejen las relaciones que pudieron ser observadas, las cuales serán almacenadas en un diagrama de influencia.
\item Modificar la estrategia considerando los efectos posibles de cada acción que fueron aprendidos, para esto se usará el Diagrama de Influencia previamente construido. 
\item Comparar el desempeño versus lo que se haría si se conociera el modelo con detalle.
\item Extender al caso de número de variables no conocido.
\end{itemize}
\bibliographystyle{apalike}
\bibliography{/Users/MauricioGS1/INAOE/Segundo_Semestre/Propuesta/Bibliografia.bib}
\end{document}
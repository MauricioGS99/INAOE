\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish, mexico]{babel}
\usepackage{listings}
\usepackage{breakcites}
\usepackage{dsfont}
\usepackage{hyperref}
\usepackage{amssymb,amsthm,amsmath,latexsym}
\usepackage[margin=1.5cm]{geometry}
\usepackage{natbib}
%\bibliographystyle{stylename}
%\usepackage{fancyhdr}
%\pagestyle{fancy}
\theoremstyle{plain}
\newtheorem{teo}{Teorema}
\newtheorem{prop}[teo]{Proposición}
\newtheorem{defi}[teo]{Definición}
\newtheorem{obs}[teo]{Observación}
\newtheorem{lem}[teo]{Lema}
\newtheorem{cor}[teo]{Corolario}
\usepackage[pdftex]{color,graphicx}
\usepackage{tikz}
\usetikzlibrary{calc}
%\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\title{Problemas de Decisión bajo Incertidumbre: el caso de estructura causal.}
\author{Mauricio Gonzalez Soto}
\begin{document}
%\nocite{*}
\maketitle
\section{Introducción}
Debido al enorme número de factores diversos que están involucrados en nuestro entorno, constántemente nos vemos forzados a tomar decisiones cuyas consecuencias son inciertas (\cite{danks2014unifying}). Esa misma realidad, altamente compleja, contiene una serie de relaciones causa-efecto que podemos utilizar al momento de tomar decisiones. El conocimiento causal permite preguntarnos  \textit{qué pasaría si...} (\cite{stalnaker2016knowledge}) y predecir las consecuencias de nuestros actos. Por desgracia, es difícil que contemos con la información necesaria para llevar a cabo estas predicciones de manera correcta, a lo más, podemos contar con estimaciones sobre lo probable que es la ocurrencia de algún evento incierto dada cierta acción.\\
\\
\indent La Teoría de la Decisión bajo Incertidumbre, desarrollada en los trabajos de \cite{von1944theory}, \cite{definetti1930}, \cite{definetti1937}, \cite{savage1954the}, \cite{bernardo2000bayesian}, considera a un tomador de decisiones que se enfrenta al problema de escoger una de entre varias opciones (o acciones) posibles en un escenario incierto, el cual influirá en las consecuencias de las acciones. Para resolver este problema a partir de una serie de axiomas se propone un criterio formal de elección, el cual consiste en la maximización de la utilidad esperada.\\
\\
\indent La utilidad esperada, como su nombre lo indica es el valor esperado, o promedio, de la utilidad que le producen al tomador de decisiones las consecuencias de sus acciones; para poder calcularla, es necesario contar con estimaciones de la probabilidad de ocurrencia de ciertos eventos inciertos. El Teorema de Von Neuman-Morgenstern, garantiza la existencia de una función de utilidad si un tomador de decisiones conoce las probabilidades de los eventos, entonces  la relación de preferencias del agente es equivalente al orden que impone la utilidad esperada respecto a esta función y las probabilidades conocidas, por lo que la mejor decisión a tomar es aquella que maximice esta cantidad.\\

\indent Por otro lado, el Teorema de DeFinnetti supone conocida la utilidad para el agente y el resultado garantiza la existencia de una medida de probabilidad (subjetiva) tal que la relación de preferencias es equivalente a maximizar la utilidad respecto a esta medida. De esta manera, se resuelve parcialmente el problema de toma de decisiones, pues si por un lado se cuenta con las probabilidades de eventos inciertos el Teorema de von Neumann devuelve la utilidad, y si se cuenta con la utilidad para el tomador de decisiones, DeFinetti devuelve las probabiliddes, pero ‚por dónde empezar?  
\\
\indent El gran logro de J.L. Savage fue derivar  la utilidad y la probabilidad en conjunto en vez de utilizarlas como primitivas del modelo (\cite{gilboa2009decision}). Lo único que requiere el Teorema de Savage es una serie de axiomas de coherencia sobre la relación de preferencias de un tomador de decisiones; con esto, muestra la existencia de una función de utilidad y de una medida de probabilidad tal que la relación de preferencias es equivalente a la maximización de la utilidad esperada. Existen otros criterios de optimalidad cuando los axiomas de Savage son cuestionados; por ejemplo, la utilidad maxmin, o la utilidad esperada de Choquet (\cite{gilboa2009decision}). \cite{gilboa2001theory} propone un nuevo paradigma de toma de decisiones en el cual los agentes toman decisiones haciendo analogías a eventos pasados en los cuales tuvieron un buen desempeño. Estas teorías, aunque interesantes, no serán abordadas en este trabajo sino que se mencionan sólo por completez.\\
\\
\indent En diversas ocasiones, un tomador de decisiones no tiene a su alcance todos los parámetros (probabilidades de los eventos), pero puede intentar \textit{aprenderlos} del mismo entorno, sobre esto ya se ha dicho mucho en el área de Aprendizaje por Refuerzo (\cite{sutton1998reinforcement}). Una de las grandes limitaciones de estos métodos es que aprenden formas de actuar que son puramente reactivas; es decir, no capturan, ni intentan, la estructura del ambiente. Un caso particular de esta estructura se da en el caso en el cual el tomador de decisiones sabe, o cree, que en el ambiente en el cual se llevan a cabo sus decisiones existen relaciones causa-efecto.
\section{Motivación}
Las relaciones causa-efecto\footnote{Entendiendo causalidad como la define \cite{spirtes2000causation}; es decir, como una relación transitiva, irreflexiva y antisimétrica entre eventos, de manera que sucede uno y esto causa que otro evento sea producido.} son de gran utilidad en problemas de decisión, pues conociendo los \textit{efectos} de las posibles decisiones a tomar, el agente puede planear mejor sus acciones (\cite{hagmayer2013repeated},\cite{pearlwhy}). Además, las relaciones causales son un tipo de \textit{estructura} del ambiente, la cual puede utilizarse para que un agente pueda razonar sobre su entorno. De hecho, se ha estudiado el caso de agentes que son racionales en un entorno causal (\cite{board2006equivalence}). Además, en el área de la Economía conocida como Economía Conductual (Behavioral Economics) es un problema interesante el dotar agentes que tienen un comportamiento incoherente en el tiempo (\cite{kleinberg2014time}) con incentivos, lo cual se puede hacer si se conocen una estructura de dependencia entre acciones y recompensas (\cite{albers2016motivating}). \\
\\
\indent La información causal por sí sola nos ayuda a los seres humanos a tomar decisiones, pues resulta que los seres humanos utilizan información causal al tomar decisiones; además, modifican la información causal previa que tenían del ambiente conforme interactúan con este (\cite{hagmayer2013repeated}). Además, este conocimiento causal es utilizado de manera correcta por los seres humanos para escoger las acciones que lleven a cierto resultado deseado (\cite{sloman2006causal}, \cite{nichols2007decision}, \cite{meder2010observing}, \cite{hagmayer2013repeated}, \cite{danks2014unifying}). Aunque, los seres humanos no son perfectos al estimar la fuerza de los efectos, o violan el supuesto Markoviano (\cite{rottman2014reasoning}). \\
\\
\indent De la misma manera en la que a los seres humanos nos ayuda contar con información causal, \cite{lattimoreNIPS2016} muestran que un agente, un tomador de decisiones, que cuenta con un modelo causal puede encontrar de manera más rápida la acción óptima en un contexto incierto. En su trabajo muestran, empírica y teóricamente, que contar con un modelo causal lleva a una mejor toma de decisiones que si sólo se realizaran búsquedas asociativas.\\
\\
\indent Han existido diversos intentos de formalizar una Teoría de Decisión que incorpore información causal, como han sido los trabajos de \cite{joyce1999foundations}, \cite{board2006equivalence}, \cite{joyce2012regret}, \cite{ahmed2012push}, \cite{rottman2014reasoning}, \cite{soares2015toward}, \cite{stalnaker2016knowledge}, los cuales hacen uso del “razonamiento contrafactual” para proponer una manera de tomar decisiones a la luz de “lo que hubiera pasado si...”. Estos trabajos tienen ciertas limitaciones filosóficas y conceptuales, pues ignoran el caso en el cual las acciones de un tomador de decisiones están correlacionadas (pero no causalmente conectadas) con algunas partes del ambiente, además de la dificultad que implica la construcción de un modelo causal. \\
\\
\indent Teoría de Juegos (\cite{osborne1994course}) es un área de las matemáticas que los economistas y otros científicos sociales utilizan para modelar situaciones de interacción estratégica; es decir, problemas de decisión en los cuales importa no solo las acciones y preferencias de un sólo agente sino las de otros. En particular, en esta área existen los llamados \textit{juegos Bayesianos}, también conocidos como Juegos Extensivos con Información Incompleta (\cite{osborne1994course}, \cite{10.1007/978-94-010-0189-2_25}),  en los cuales cada jugador tiene creencias \textit{a priori} sobre algunos aspectos del ambiente (en las aplicaciones de economía estas creencias suelen versar sobre las recompensas o sobre las estrategias de otros jugadores). En general, los juegos Bayesianos pertenecen a una clase de juegos llamados juegos estratégicos.\\
\\
Las creencias que suele tener un jugador suelen ser sobre ciertos aspectos; por ejemplo, creencias sobre las acciones de los otros jugadores (\cite{costa2008stated}), creencias sobre el estado del mundo (\cite{dominitz2009empirical}) y creencias sobre las creencias de los otros jugadores
\\
\cite{tingley2010belief}

\section{Justificación}
Contar con información sobre la estructura causal de cierto entorno puede hacer que un proceso de toma de decisiones se lleve a cabo de manera eficiente; en el trabajo de \cite{lattimoreNIPS2016} se muestra cómo al contar con un modelo causal del ambiente se pueden encontrar acciones óptimas de manera más rápida que si sólo se llevara a cabo una exploración a ciegas con tal de encontrar la mejor acción como llevan a cabo \cite{audibert2010best}. \cite{lattimoreNIPS2016} consideran el caso en el cual un tomador de decisiones quiere maximizar cierta variable de recompensa y las acciones que tiene a su disposición el agente están relacionadas de manera causal con la variable recompensa y entre sí.\\
\\
\indent Se sabe que los seres humanos conciben sus acciones en el mundo como \textit{intervenciones} sobre este (\cite{hagmayer2009decision}). Siguiendo esta idea,  \cite{lattimoreNIPS2016} consideran las acciones disponibles a un agente inteligente como \textit{intervenciones} posibles en un modelo causal; la dinámica que proponen consiste en que el agente realice una acción y posterior a esto se observa el valor de la variable recompensa así como la realización de las otras variables del modelo que no fueron intervenidas; en esto consiste una \textit{ronda}. En la siguiente ronda, el entorno vuelve a su estado inicial y el agente selecciona otra posible intervención y vuelve a observar estas variables. Esta dinámica de rondas repetidas en la que cada ronda inicia sin tomar en cuenta lo sucedido en la anterior lleva a los autores a modelar el problema como escoger brazos en una máquina tragamonedas (conocidas como \textit{bandits} en la literatura), observar el pago y moverse a una máquina nueva. El algoritmo que desarrollan identifica la \textit{intervención óptima} después de un número $T$ de rondas fijado por el agente y permite hacerlo de manera más rápida que los algoritmos del estado del arte.\\
\\
\indent Lo que este trabajo señala es que  la luz de un modelo causal se pueden tomar decisiones que maximicen cierta variable de pago de manera más rápida que los métodos que no incorporan relaciones causales. La limitación que tiene este trabajo es suponer conocido de antemano el modelo causal, pero para modelar un escenario más realista es necesario suponer no conocido el modelo causal e intentar aprender sobre éste a partir de las interacciones mismas con el ambiente; de hecho es, en parte, como operamos los seres humanos (\cite{hagmayer2013repeated}). La importancia del razonamiento causal para el desarrollo de agentes inteligentes está detallada y justificada en \cite{lake2017building}.\\
\\
\indent Modificar uno a uno los vértices, o por decirlo de otra forma, hacer actualizaciones locales, como se hace en \cite{lattimoreNIPS2016} tiene sentido pues existe evidencia de que los seres humanos se enfocan en aprender aspectos locales de estructuras causales (\cite{danks2014unifying}) y posteriormente unificar estos aspectos en una sola estructura coherente (\cite{fernbach2009causal}, \cite{waldmann2008causal}, \cite{wellen2012learning}). Además, tomar en cuenta la restricción de sólo tener una decisión por ronda es realista, pues problemas de decisión secuencial pueden modelarse como sucesiones de decisiones de una sola acción, además de que siempre es posible considerar varias acciones simultáneas como una sola que las englobe.\\
\\
\indent A diferencia de lo que sucede en Aprendizaje por Refuerzo (RL por sus siglas en inglés), en donde el agente lleva a cabo una acción y observa una señal de recompensa del ambiente, lo que se propone es a observar una \textit{jugada} de la Naturaleza; es decir, toda una acción y no sólo una cuantificación de lo devuelto por el entorno. Diseñar una señal de recompensa es un problema difícil en general (\cite{sutton1998reinforcement},\cite{dewey2014reinforcement}, \cite{DRLnotwork}), pues es la manera de especificarle al agente qué debe hacer, pero no cómo. Además, pudiera ocurrir que la señal de recompensa sea construída de modo que oculte las relaciones causales al agente, por eso se opta por observar lo que ocurre afuera como jugadas y que sea el agente quien asigne una utilidad a los resultados finales del juego.


\section{Problema de investigación}
Adqusición y uso de información causal en problemas de toma de decisiónes secuenciales bajo incertidumbre.
\section{Planteamiento del Problema}
Suponemos un ambiente que está regido por un modelo causal, y suponemos que este es desconocido, pero fijo y además cumple que todas las variables se encuentran contenidas en él (suficiencia causal).\\
\\
\indent Un problema de decisión bajo incertidumbre (de una etapa) consiste en un conjunto de acciones, un conjunto de consecuencias y un conjunto de \textit{eventos inciertos}; la interpretación estándar (\cite{bernardo2000bayesian}, \cite{gilboa2009decision}) es que el agente escogerá una de estas acciones, luego ocurrirá uno de estos eventos inciertos y será esto lo que determine la consecuencia. Suponer que un modelo causal exista y opere sobre este ambiente implica que éste controle la relación entre los eventos inciertos y las consecuencias de éste, lo cual queda codificado en probabilidades; de este modo, si se conoce el modelo causal, se conocen las probabilidades de ocurrencia de las consecuencias dada la acción escogida y el evento incierto. De esta manera, se puede determinar la acción óptima (o serie de acciones) mediante la maximización de la utilidad esperada, pues este es el único criterio de solución que es coherente con los axiomas de decisión de \cite{savage1954the}.\\
\\
\indent Cuando el modelo causal no es conocido por el tomador de decisiones, tampoco lo son las probabilidades de los efectos dadas las causas, por lo que no se puede calcular la utilidad esperada. Entonces, el camino que se propone es aprender los parámetros a partir de la información que provee el ambiente posterior a cada interacción con este. Sabemos que un problema de decisión bajo incertidumbre puede resolverse con algunas de las técnicas ya conocidas en el área de Aprendizaje por Refuerzo (\cite{sutton1998reinforcement}), resulta además que una política óptima aprendida con estas técnicas alcanza la MUE (\cite{webb2007game}). Lo que estas técnicas ignoran es cuando el agente sabe que su entorno tiene cierta estructura particular, y se desea utilizar esta información para aprender los parámetros del modelo y tomar decisiones de manera correcta. En este caso, la estructura es la que está dada por las relaciones causa-efecto en el ambiente.\\
\\
\indent Para llevar a cabo el proceso aprendizaje dotamos al agente con  \textit{creencias} sobre la estructura causal de su entorno las cuales se irán actualizando conforme el agente interactue con éste. Estas creencias pueden considerarse como un modelo causal \textit{propio} del agente, pues el agente utilizará este modelo causal para la toma de decisiones, que por construcción irá acercándose cada vez más al modelo causal verdadero. El problema de la actualización de creencias puede estudiarse en dos casos distintos: si el número de variables en el modelo causal es conocido por el agente, entonces podemos representar el modelo causal mediante matrices de tamaño fijo y llevar a cabo actualizaciones en las entradas de estas; pero si el número de variables es desconocido por el tomador de decisiones, un camino a seguir es utilizar un enfoque Bayesiano no-paramétrico y considerar distribuciones sobre un espacio de grafos; este problema parece tener una complejidad alta. Enfoques Bayesianos no-paramétricos para descubrimiento causal han sido explorados en \cite{karabatsos2012bayesian}.\\
\\
\indent Para modelar la interacción del tomador de decisiones con su entorno, vamos a asumir que el agente está interactuando con un ente abstracto al que le llamaremos Naturaleza y que la dinámica de interacción consiste en un \textit{juego}. A diferencia de lo que se hace en Aprendizaje por Refuerzo en donde se considera que el agente está “solo con su entorno”, aquí consideramos que todo lo que proviene de afuera del agente son jugadas de este ente abstracto. En el contexto de Teoría de Juegos, los juegos que permiten que el agente tenga creencias información incompleta se llaman \textit{Juegos Estocásticos}, los cuales fueron introducidos por \cite{shapley1953stochastic} y generalizan los Procesos de Decisión Markovianos (MDP), así como los juegos repetido, pues un MDP es simplemente un juego estocástico con un solo jugador mientras que un juego repetido es un juego estocástico de una sola etapa (\cite{shoham2008multiagent}).\\
\\
\indent En resumen, el modelo consiste en traducir un problema de toma de decisiones bajo incertidumbre en un juego Bayesiano entre el tomador de decisiones y la Naturaleza donde esta última va a muestrear sus acciones a partir del modelo causal que opera en el entorno y que establece las relaciones causales entre variables así como entre acciones y variables. Queremos que a lo largo de las jugadas (o de repeticiones de los juegos) el jugador vaya actualizando sus creencias causales y descubriendo ese modelo causal; es decir, se necesita que las creencias actualizadas del jugador converjan al verdadero modelo. Además, utilizando el concepto de \textit{estrategias mixtas} el jugador puede tomar ciertas acciones de manera aleatoria, lo que introduce el concepto de \textit{exploración} proveniente del área de RL. Lo que esperamos tener al final de un cierto número de rondas de aprendizaje es un \textit{diagrama de influencia causal}, que consistirá en la extensión al caso causal de los diagramas de influencia tradicionales.\\
\\
\indent Un primer planteamiento sería considerar que las acciones de la naturaleza son completamente \textit{desinteresadas}; es decir, que la naturaleza no tiene ningún objetivo en particular. En \cite{eberhardt2008causal} el problema de descubrimiento causal es planteado también como un juego, en el cual la naturaleza escoge desde el inicio el modelo causal \textit{real} y el jugador debe escoger intervenciones a llevar a cabo con tal de descubrir el modelo causal. En este caso el objetivo es descubrir el modelo causal, no el aspecto de toma de decisiones.
\section{Trabajo Previo}
\subsection{Causalidad y Decisiones}
Existen trabajos que utilizan en conjunto inferencia causal junto con toma de decisiones; por ejemplo \cite{heckerman1995decision} argumenta que los trabajos usuales sobre causalidad no contienen primitivas suficientemente básicas, por lo que plantea el problema de inferencia causal como uno de toma de decisiones.\\
\\
\indent Por otro lado, \cite{dawid2002influence} explica cómo plantear un problema de inferencia causal utilizando diagramas de influencia, los cuales son una extensión de las redes Bayesianas para incluir nodos de decisión, y los cuales pueden utilizarse para descubrir las acciones óptimas en un problema de decisión tradicional (sí, aquella serie de acciones que obtiene la máxima utilidad esperada). El interés del autor es utilizar la representación de diagramas de influencia para \textit{interrogar} el fenómeno. En nuestro caso, el objetivo es \textit{construir} este diagrama mediante un ciclo de decisión-observación.\\
\\
\indent \cite{koller2003multi} utilizan diagramas de influencia para encontrar estrategias relevantes en juegos multi-agente, con lo cual descomponen un juego grande en varios juegos más chicos que se resuelven de manera secuencial.\\
\\
\indent \cite{board2006equivalence} define la racionalidad causal en juegos, concepto que toma en cuenta lo que se espera que otros jugadores hagan; es decir, toma en cuenta que las acciones de un jugador puedan tener efectos en las estrategias de los otros jugadores. Resulta que este concepto es equivalente a la racionalidad bayesiana estándar bajo el supuesto de independencia causal.\\
\\
\indent \cite{soares2015toward} compara, desde un punto de vista epistemológico, la toma de decisiones apoyada en evidencia versus el uso de uso de razonamiento contrafactual en la toma de decisiones, aunque conceptualmente esta última permite llevar a cabo razonamientos más complejos el problema que se presenta en la práctica es precisamente la construcción del modelo causal a partir del cual se van a tomar decisiones.
\subsection{Identificación de intervenciones óptimas}
\indent Por otro lado, desde un punto de vista computacional, \cite{lattimoreNIPS2016} atacan el problema de toma de decisiones en entornos causales pero bajo un modelo causal conocido; en este modelo, las acciones a escoger son intervenciones posibles en el grafo causal y lo que se busca es maximizar cierta variable de recompensa que está influenciada directamente por el modelo causal. La optimalidad de su acción está determinada en términos del \textit{regret} mínimo, que es básicamente un valor esperado. Esta medida de optimalidad no está relacionada con ninguna función de utilidad asociada a un agente y esto restringe que el mismo problema se resuelva con distintos fines en mente. En el artículo consideran dos casos posibles: un caso en el cual hay $N$ causas, independientes entre sí, y una variable a la que estas causas afectan; en el caso general, en el cual las causas pueden afectarse entre sí, los autores utilizan un estimador por importancia truncado para la selección de acciones en cada ronda con un nivel fijo de truncamiento. En este trabajo se asume que el modelo causal es conocido y plantean como trabajo futuro el caso en el cual se desconoce el modelo, que es precisamente el caso que se busca atacar aquí.\\
\\
\indent El trabajo de \cite{lattimoreNIPS2016}, en general, considera el aspecto de toma de decisiones en línea en un entorno incierto y modelan esto como bandits; al respecto, existen una serie de trabajos que son capaces de encontrar el \textit{mejor brazo} a escoger en un número finito de rondas, pero estos modelos son puramente asociativos y no utilizan información adicional del ambiente, que en el caso de los Lattimore esta información adicional está dada por las relaciones causa efecto que ocurren en el ambiente. Este trabajo se encuentra en la intersección de inferencia causal y de descubrimiento de mejor brazo bajo restricciones presupuestales; en este sentido encontramos los trabajos de \cite{audibert2010best}, \cite{jamieson2014lil},  \cite{jamieson2014best},  \cite{ortega2014generalized}, \cite{chen2015optimal},\cite{carpentier2016tight},  \cite{russo2016simple},  \cite{kaufmann2016complexity}. Por otro lado, en cuanto al aprendizaje de modelos causales a partir de datos o experimentos están los trabajos de \cite{eberhardt2008almost}, \cite{mooij2016distinguishing}, \cite{hyttinen2013experiment}, \cite{hauser2012two}, \cite{loh2014high}, \cite{shanmugam2015learning}.\\
\\
\indent El trabajo de \cite{sen2017identifying} considera el problema de la mejor de entre varias posibles intervenciones \textit{suaves} en un modelo causal, del cual sólo se conoce una parte. Después de $T$ rondas de intervención, se busca encontrar la mejor intervención sobre alguna una de las variables que está en la parte desconocida del modelo. Una gran diferencia de este trabajo respecto a los trabajos clásicos de identificación del mejor brazo como \cite{audibert2010best} es considerar el \textit{filtrado de información} entre brazos, pues gracias al modelo causal los valores muestreados de un brazo (intervención) pueden aportar información sobre los otros
mejora a \cite{lattimoreNIPS2016} y a \cite{audibert2010best}. Uno de las mejores respecto al trabajo de \cite{lattimoreNIPS2016} es que el nivel de truncamiento es adaptativo en cada ronda de modo que balancea sesgo y varianza. Aunque los algoritmos de \cite{sen2017identifying} mejoran los de \cite{lattimoreNIPS2016} en el mismo caso, siguen requiriendo conocer las distribuciones condicinales y las marginales
\subsection{Juegos, decisiones y actualización de creencias}
\indent Modelar problemas de decisión como un juego de manera que se vaya aprendiendo a realizar una tarea ha sido explorado previamente en \cite{werling2015job}, quienes modelan un problema de clasificación \textit{on-line} como un juego, pero en el cual las acciones del tomador de decisiones consisten en utilizar un oráculo para clasificar las observaciones iniciales. De manera similar, \cite{javdani2014near} utilizan teoría de la decisión Bayesiana para seleccionar experimentos que proporcionen la mayor información respecto a un fenómeno.\\
\\
\indent \cite{larrouy2017mindreading} estudian la formación de creencias a partir de las acciones observadas y definen el concepto de \textit{mindreading}; es decir, poder adelantarse a las creencias que el otro jugador tomará en cuenta a la hora de tomar sus decisiones.\\
\\
\indent La relación entre Teoría de Juegos, toma de decisiones e incorporación de información adicional (causal) parece muy clara, aunque no ha sido particularmente explotada. A lo más, los trabajos plantean el problema per se de inferencia causal \textit{como} un juego. Por ejemplo, \cite{heckerman1995decision}, \cite{eberhardt2008causal}  En nuestro caso, lo que se propone es jugar un juego para el cual existan relaciones causales de fondo y utilizar lo que se pueda aprender de estas.
\\
\cite{di2013predictive}
\\
\cite{tingley2010belief}
\\
\cite{10.1007/978-94-010-0189-2_25}
\\
\cite{harper1988causal}
\section{Objetivos}
Para llevar a cabo lo anterior se necesita desarrollar:
\begin{itemize}
\item Una forma de especificar creencias sobre estructura causal; esto puede ser mediante una distribución probabilista sobre un espacio de grafos. Podemos suponer que el número de variables es conocido de antemano, con lo cual podríamos limitarnos a trabajar sobre distribuciones de matrices de tamaño fijo. Si se permite que el número de variables sea arbitrario/desconocido, tendríamos que operar con modelos Bayesianos no paramétricos.
\item Un criterio de actualización de creencias causales que además debe cumplir la propiedad de que converge al verdadero modelo causal así como ser coherente con estudios de la psicología de la formación de creencias (\cite{larrouy2017mindreading}). Es importante mencionar que los juegos Bayesianos, en su definición estándar, proveen un mecanismo para la actualización general de creencias, pero se necesita una manera de actualizar creencias que haga uso de la estructura causal misma.
\item Un criterio de solución del problema: Si no es posible esperar hasta la convergencia del modelo, sí debemos garantizar que las decisiones tomadas con el modelo causal aprendido hasta cierta ronda aproximen la utilidad máxima esperada.
\item Una manera de construir un diagrama de influencia causal que además permita \textit{exportar} el conocimiento adquirido para problemas similares; de esta manera, ya sabríamos directamente cómo actuar conociendo el modelo causal.
\end{itemize}
\section{Ejemplo}
Supongamos que un paciente que llega a un hospital puede tener la nfermedad $A$ con probabilidad $p_A$ o la enfermedad $B$ con probabilidad $p_B=1-p_A$. El médico de guardia tiene a su alcance tres tratamientos posibles: cirugía, fármaco o nada. En caso de no hacer nada, el paciente morirá con una probabilidad $p_{dn}=0.8$ y sobrevivirá con una probabilidad $1-p_d$. Sin importar la enfermedad, el paciente puede morir durante la cirugía con probabilidad $p_{dc}=0.5$. De la misma manera, el medicamento producirá una reacción alérgica mortal con probabilidad $p_{df}=0.2$\\
\\
\indent Si el paciente tenía la enfermedad $A$, y no muere de una reacción alérgica al fármaco, entonces el fármaco le curará con una probabilidad de $p_{sf}=0.9$. Si el paciente tenía la enfermedad $B$, entonces el fármaco no le curará y morirá con la misma probabilidad que si no se hubiera hecho nada.\\
\\
\indent Por otro lado, si el paciente sobrevive a la cirugía, ésta le curará con una probabilidad de $0.5$ si el paciente tenía la enfermedad $A$. Si el paciente tenía la enfermedad $B$, entonces ésta lo curará con probabilidad de $0.6$. \qed
\\
\\
\indent Entonces, en este ejemplo, tenemos que el juego consiste en el médico, y en la Naturaleza. Las acciones disponibles al médico son:
\[ A= \{ \textrm{fármaco},  \textrm{cirugía}, \textrm{nada} \}. \]
Por otro lado, las jugadas de la Naturaleza son: 
\[ A= \{ \textrm{A, B, vive, muere} \}. \] 
El juego consiste en lo siguiente:
\begin{itemize}
\item Primero, la naturaleza hace su jugada, lo cual determina qué enfermedad tenía el paciente. 
\item Después, el médico decide qué hacer. 
\item Posteriormente, la Naturaleza lanzará una moneda cargada que determinará si el paciente sobrevive. Notemos que, de manera latente, es un modelo causal el que determina que el fármaco no cura la enfermedad B, o que éste causa alergias, etc.
\end{itemize}
Sabemos que el médico fue a la escuela de medicina, de donde posee una gran cantidad de información (causal) a priori, pero puede que se esté enfrentando a una nueva enfermedad, es decir, no conoce realmente las probabilidades de muerte ni los casos en que el fármaco no actua.\\
\\
Lo que se desea es que a partir de este caso (juego), o de varios más, pueda actualizar su conocimiento causal para la siguiente ocasión en la que deba enfrentarse a  un problema similar.\\
\\
Notemos las similaridades que existen entre este ejemplo y el problema atacado por \cite{lattimoreNIPS2016}, quienes buscan escoger la \textit{mejor intervención} en un modelo causal dado con tal de maximizar cierta recompensa. En su modelo, un agente puede intervenir el modelo, y observar la recompensa y luego empezar desde cero; en nuestro caso, llega un paciente, el médico propone una acción, observa los efectos y procede con el siguiente paciente. El médico no conoce el modelo, que es la situación que \cite{lattimoreNIPS2016} dejan como trabajo futuro al final de su artículo. \\
\\
Para ser coherentes con el planteamiento de \cite{lattimoreNIPS2016} la actualización de creencias debe suceder al final de uno (o varios) juegos; además, el caso secuencial se atacará posteriormente.\\
\\
% Node styles
\tikzset{
% Two node styles for game trees: solid and hollow
solid node/.style={circle,draw,inner sep=1.5,fill=black},
hollow node/.style={circle,draw,inner sep=1.5}
}
\begin{tikzpicture}[scale=1.5,font=\footnotesize]
% Specify spacing for each level of the tree
\tikzstyle{level 1}=[level distance=15mm,sibling distance=35mm]
\tikzstyle{level 2}=[level distance=15mm,sibling distance=15mm]
% The Tree
\node(0)[solid node,label=above:{$N$}]{}
child{node(1)[solid node]{}
child{node[hollow node,label=below:{$(a,b)$}]{} edge from parent node[left]{$f$}}
child{node[hollow node,label=below:{$(c,d)$}]{} edge from parent node[right]{$c$}}
child{node[hollow node,label=below:{$(c,d)$}]{} edge from parent node[right]{$n$}}
edge from parent node[left,xshift=-3]{$A$}
}
child{node(2)[solid node]{}
child{node[hollow node,label=below:{$(e,f)$}]{} edge from parent node[left]{$f$}}
child{node[hollow node,label=below:{$(g,h)$}]{} edge from parent node[right]{$c$}}
child{node[hollow node,label=below:{$(c,d)$}]{} edge from parent node[right]{$n$}}
edge from parent node[right,xshift=3]{$B$}
};
% information set
\draw[dashed,rounded corners=10]($(1) + (-.2,.25)$)rectangle($(2) +(.2,-.25)$);
% specify mover at 2nd information set
\node at ($(1)!.5!(2)$) {$M$};
\end{tikzpicture}
\section{Metodología de Trabajo}
Para cumplir con los objetivos planteados antes, se propone:
\begin{itemize}
\item Consideramos un problema de decisión bajo incertidumbre que se desarrolla en un entorno regido por un modelo causal. En una primera etapa, consideramos que el número de variables que están contenidas en ese modelo es finito y conocido para el tomador de decisiones.
\item Para este caso finito, se debe encontrar una manera para incorporar conocimiento causal inicial, o previo, el cual debe ser coherente con lo que se conoce, o no, sobre el problema, además de ser coherente con la manera en la que los seres humanos formamos creencias (\cite{larrouy2017mindreading}).
\item Este conocimiento causal inicial debe ser expresado en términos de probabilidades y para esto se construirá un \textit{prior} que consiste en una distribución sobre un espacio de matrices. Recordemos que una matriz (que cumple ciertas características) define un grafo, por lo que tener de esta manera estaremos especificando las probabilidades que un agente asigna, de manera subjetiva, a distintos modelos causales. 
\item De acuerdo a las características del problema de decisión se planteará un juego de dos jugadores, uno de los cuales será el tomador de decisiones inicial, y el otro será un ente abstracto llamado Naturaleza que, suponemos, conoce el modelo causal y lleva a cabo sus jugadas a partir de lo dictado por éste. Los juegos sucederán de manera repetida para poder aprender de éste.
\item Definir un número de juegos de observación, dentro de estos juegos el tomador de decisiones no modificará sus creencias causales, aunque éstas lo obliguen a tener un desempeño no óptimo.
\item Definir una estrategia para el tomador de decisiones a partir del conocimiento causal que tenga hasta ese momento; una \textit{estrategia mixta} permitiría explorar el ambiente con tal de explorar el ambiente de manera amplia.
\item A partir de lo observado en la ronda de juegos de observación, se debe actualizar las creencias causales de manera que se reflejen las relaciones que pudieron ser observadas, las cuales serán almacenadas en un diagrama de influencia.
\item Modificar la estrategia considerando los efectos posibles de cada acción que fueron aprendidos, para esto se usará el Diagrama de Influencia previamente construido. 
\item Comparar el desempeño versus lo que se haría si se conociera el modelo con detalle.
\item Extender al caso de número de variables no conocido.
\end{itemize}
\bibliographystyle{apalike}
\bibliography{/Users/MauricioGS1/INAOE/Segundo_Semestre/Propuesta/Bibliografia.bib}
\end{document}
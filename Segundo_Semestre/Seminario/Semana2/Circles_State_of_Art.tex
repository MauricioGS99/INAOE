\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish, mexico]{babel}
\usepackage{listings}
\usepackage{breakcites}
\usepackage{dsfont}
\usepackage{hyperref}
\usepackage{amssymb,amsthm,amsmath,latexsym}
\usepackage[margin=1.5cm]{geometry}
\usepackage{natbib}
%\bibliographystyle{stylename}
%\usepackage{fancyhdr}
%\pagestyle{fancy}
\theoremstyle{plain}
\newtheorem{teo}{Teorema}
\newtheorem{prop}[teo]{Proposición}
\newtheorem{defi}[teo]{Definición}
\newtheorem{obs}[teo]{Observación}
\newtheorem{lem}[teo]{Lema}
\newtheorem{cor}[teo]{Corolario}
\usepackage[pdftex]{color,graphicx}
\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\title{State of The Art Circles}
\author{Mauricio Gonzalez Soto}
\begin{document}
%\nocite{*}
\maketitle
\section{Outer Circle}
\begin{itemize}
\item (\cite{suppes1970probabilistic})
\item \cite{holland1986statistics}
\item \cite{sutton1998reinforcement}
\item Causal decision theory (\cite{joyce1999foundations}): Making decisions using causal knowledge; i.e. I know that $A$ \textit{causes} $B$, so it can be predicted what will happen if $A$ is chosen, or not, over other options. 
\item (\cite{spirtes2000causation})
\item \cite{pearl2009causality},
\item Causal graphical models ( \cite{koller2009probabilistic}): Causal semantics over probabilistic graphical models.
\item Decision Theory Under Uncertainty (\cite{gilboa2009decision}).
\item \cite{pearl1988probabilistic}
\item \cite{van2012reinforcement}
\item  \cite{danks2014unifying}
\item \cite{gershman2015reinforcement}
\item \cite{lopez2015towards}
\item \cite{lake2017building}
\end{itemize}
\section{Middle Circle}
\begin{itemize}
\item \cite{watkins1992q}
\item \cite{baxter2001infinite}
\item \cite{boyan2002technical}
\item Decision problems and causal models: \cite{dawid2002influence} show how causal Bayesian Nets can be augmented with decision nodes as to model decision problems that use causal information.
\item \cite{konda2003onactor}
\item \cite{sanjana2003bayesian}
\item \cite{panait2005cooperative}
\item \cite{de2006learning}
\item \cite{shoham2007if}
\item \cite{richter2007natural}
\item \cite{krynski2007role}
\item \cite{gopnik2007bayesian}
\item \cite{busoniu2008comprehensive}
\item \cite{hagmayer2009decision}
\item \cite{meder2009role}
\item \cite{meder2010observing}
\item \cite{bucsoniu2010multi}
\item \cite{kemp2010learning}
\item \cite{hasselt2010double}
\item On-line learning in causal models(\cite{wellen2012learning})):  Causal learning in an on-line setting has been framed in terms of causal graphical models, where in a causal graphical model edges are added or removed in a prediction-error loop.
\item \cite{grondman2012survey}
\item \cite{nowe2012game}
\item \cite{mnih2013playing}
\item \cite{guo2014deep}
\item \cite{silver2014deterministic}
\item Policy Gradients  \cite{DBLP:journals/corr/MnihBMGLHSK16}: the authors of the original DQN paper who have shown Policy Gradients to work better than Q Learning when tuned well. PG is preferred because it is end-to-end: there’s an explicit policy and a principled approach that directly optimizes the expected reward.
\item \cite{lopez2015towards}
\item \cite{krynski2007role} Human reasoning under uncertainty naturally operates over causa mental models and statistical data supports correct Bayesian inference only when they can be incorporated into a causal model. 
\item \cite{van2016deep}
\item \cite{lakkarajuNIPS2016}
\item \cite{lakkarajuNIPS2016}
\item \cite{toulisNIPS2016}
\item \cite{kulkarniNIPS2016}
\item \cite{foersterNIPS2016}
\item \cite{DBLP:journals/corr/SchulmanMLJA15}
\item \cite{goudet2017learning}
\item \cite{firoiu2017beating}
\item \cite{leibo2017multi}
\item \cite{amarjyoti2017deep}
\item \cite{nguyen2017}
\item \cite{wei2017}
\item \cite{wang2017}
\item \cite{swaminathan2017}
\item \cite{papini2017}
\item \cite{lanctot2017}
\item \cite{ding2017}
\item \cite{vanseijen2017}
\item \cite{christiano2017}
\item \cite{louizos2017}
\item \cite{rahmanian2017}
\item \cite{DBLP:journals/corr/HuangT17}
\item \cite{DBLP:journals/corr/LevineFDA15}
\item \cite{DBLP:journals/corr/GuLSL16}
\item \cite{DBLP:journals/corr/ArulkumaranDSB16}
\item \cite{DBLP:journals/corr/ZahavyBM16}
\item \cite{DBLP:journals/corr/ChenDHSSA16}
\item \cite{goudet2017learning}

\item \cite{leibo2017multi}
\item \cite{hernandez2017survey}
\item \cite{li2017deep}
\item \cite{zhang2017deeper}
\item \cite{albrecht2017autonomous}
\item \cite{pearl2018theoretical}
\end{itemize}
\section{Inner Circle}
\begin{itemize}
\item \cite{eberhardt2008causal} plantea el problema de \textit{descubrimiento causal} como un juego entre un científico vs la naturaleza en el cual la naturaleza intenta mantener ocultos sus secretos y el científico intenta descubrirlos mientras minimiza un costo. 
\item \cite{eberhardt2012number}
\item \cite{hauser2012two}
\item Causal learning through sequential decision making (\cite{hagmayer2013repeated}).
\item \cite{ortega2014generalized} 
\item \cite{bramley2015staying}
\item \cite{alon2015online} Estudian problemas de aprendizaje on-line en los cuales en cada ronda un jugador escoje una acción y recibe un \textit{loss} previamente especificado. Estudian las \textit{feedback graphs} que básicamente dicen si al ejecutar acción $i$ vemos el loss asociado a acción $j$ y estudian cómo la estructura de este grafo afecta el aprendizaje. Es principalmente un paper de estructura de grafos y el \textit{aprendizaje} se define en términos de Teoría de Juegos.
\item \cite{lattimoreNIPS2016} Quieren descubrir la mejor intervención de modo que se minimice el \textit{regret} después de $T$ rondas.
\item \cite{albrecht2016exploiting}
\item \cite{garnelo2016towards}
\item \cite{innes2018reasoning}
\end{itemize}
\newpage
\bibliographystyle{apalike}
\bibliography{/Users/MauricioGS1/INAOE/Segundo_Semestre/Propuesta/Bibliografia.bib}
\end{document}
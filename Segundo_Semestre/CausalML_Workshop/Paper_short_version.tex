\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amssymb,amsthm,amsmath,latexsym}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2018} with \usepackage[nohyperref]{icml2018} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2018}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2018}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2018}

\begin{document}

\twocolumn[
\icmltitle{Playing against Nature: causal discovery for decision making under uncertainty}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2018
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Mauricio Gonzalez-Soto}{inaoe}
\icmlauthor{Luis Enrique Sucar}{inaoe}
\icmlauthor{Hugo Jair Escalante}{inaoe}

\end{icmlauthorlist}

\icmlaffiliation{inaoe}{Department of Computer Science, National Institute of Astrophysics Optics and Electronics (INAOE), Puebla, Mexico}


\icmlcorrespondingauthor{Cieua Vvvvv}{c.vvvvv@googol.com}
\icmlcorrespondingauthor{Eee Pppp}{ep@eden.co.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Causality, Causal Inference, Game Theory, Decision under Uncertainty}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

%\begin{abstract}
%We study how a decision maker can learn and use causal information in an uncertain environment which is governed by a causal model. 
%Interaction between the decision maker and his environment is modelled as a repeated game where a player called Nature selects his actions from the causal model.
%The decision maker has beliefs over the causal model which she updates in each round. 
%\end{abstract}

\section{Introduction}
A fundamental part of intelligent reasoning  is being able to make decisions under uncertain conditions (\cite{lake2017building}, \cite{danks2014unifying}). In some cases, a decision maker who faces an uncertain environment has enough information to make choices by maximizing expected utilities. If enough information is not available, the decision maker could try to \textit{learn} from the environment by interacting with it.

Learning by interaction has been extensively studied in Reinforcement Learning \cite{sutton1998reinforcement}, but the most common used techniques are purely reactive (\cite{garnelo2016towards}) and do not consider any structure of the environment beyond what is expressable in an MDP.

Since human beings are known to learn causal graphical models in sequential decision making processes (\cite{sloman2006causal}, \cite{nichols2007decision}, \cite{meder2010observing}, \cite{hagmayer2013repeated}, \cite{danks2014unifying}), although this learning is not perfect (\cite{rottman2014reasoning}).

In this paper which we propose that an autonomous agent can learn and use causal information while interacting with an uncertain environment which is governed by a fixed \textit{causal mechanism} unknown to the agent.  

The interaction between the decision maker and his environment is modelled as a repeated game with incomplete information between a player called Nature which selects his actions from the causal model and the decision maker and propose a way for the agent to have \textit{beliefs} about the causal model that governs the environment.

\section{Related Work}
One stage decision problem where the relation between actions and consequences is given by a causal model, is analyzed by \cite{lattimoreNIPS2016} as a \textit{bandit problem}. In bandit problems an agent chooses an \textit{arm} from a slot machine, observes a reward and then moves on to the next machine which is of the same kind and whose initial settings are independent of the previous machine and action \cite{sutton1998reinforcement}.

Several algorithms exists for finding the best arm in a multi-arm bandit, such as \cite{bubeck2009pure}, \cite{audibert2010best}, \cite{gabillon2012best}, \cite{agarwal2014taming} , \cite{jamieson2014lil},  \cite{jamieson2014best},  \cite{ortega2014generalized}, \cite{chen2015optimal},\cite{carpentier2016tight},  \cite{russo2016simple},  \cite{kaufmann2016complexity}, but none of this works consider causal-governed environments.

Up to our current knowledge \cite{lattimoreNIPS2016} is the first paper to consider causal relations between the effects of actions. They consider a decision maker who must choose the best among several possible interventions on a given, and fully known, causal model. The optimality of the action in this context is in terms of the minimal regret. The case where the causal model is not known is left as future work.

By considering a causal model which is partially known and intervening variables from the unknown part and by avoiding sampling arms that are considered sub-optimal \cite{sen2017identifying} extend the work of \cite{lattimoreNIPS2016}.

The aforementioned papers assume the causal model is known to the decision makers so their work focuses on \textit{using} causal information to make good choices but the problem of \textit{acquiring} this causal knowledge is left unatacked. Here we propose to acquire, and use, causal information while interacting with the environment. 

\section{Problem setup}
By \textit{causality} we mean a stochastic binary relation between events of a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ denoted by $“\to”$ that is transitive, irreflexive and antisymmetric (\cite{spirtes2000causation}). 

A directed acyclic graph (DAG) can be used to represent all of the relations that occur in that space by considering a node for every variable that is related to another and a directed edge to express the causal relation, call this DAG $\mathcal{G}$ and consider a probability measure $P_{\mathcal{G}}$ that expresses the conditional statements from the DAG. 

We require that this measure satisfies the Markov Causal Condition, Causal Minimality and Causal Faithfulness as stated in \cite{spirtes2000causation}. The relation between $\mathbb{P}$ and $P_{\mathcal{G}}$ is given by the Manipulation Theorem of \cite{spirtes2000causation} and the Do-Calculus rules from \cite{pearl2009causality}.

Consider a Decision Problem under Uncertainty $(A,E,C,\succeq)$ where family of uncertain events $E$ and the set of consequences $C$ are causally related. We assume that the decision maker has \textit{rational preferences}, and because of this we can substitute his preferences $\succeq$ for a utility function $u$. The decision maker does not know the probabilities underlying the causal model therefore he can not calculate the expected utility of any action. 

Instead, the agent will try to learn by interaction with the environment succesive rounds of decision making. Inside each round, any response from the environment will be independent from the previous rounds, but the actions of the decision maker, which will be based upon previously acquired causal information are expected to improve the utility for the agent.

We define a game between the decision maker and a new abstract player called Nature. The base game will be the original decision problem.

Nature will be indifferent among the different possible outcomes of the game and will select its actions from the causal model. Nature having objectives to pursue (non-constant payments) will be left as future work.

\section{Belief formation and updating}
For an agent to reason about and modify his causal knowledge we endow her with a probability distribution $p(\theta)$ over a suitable space. Since we are considering causal graphical models, and for each DAG there exists a one-to-one correspondence to a matrix, one way to express beliefs about DAG's is using distributions over matrices for the structure of the graph.

Since the beliefs must behave as a \textit{local} model in a given moment, it is preferable to assign probabilities directly to causal models rather than edges in a model in order to have a fixed model when sampling from this probability assignement.

After each round of the base game, the probabilities representing causal beliefs will be updated in a Bayesian way in order to guarantee Bayesian consistency \cite{shoham2008multiagent}.
\section{Test scenario}
Consider a patient who arrives at a hospital and he can have either disease $A$ or $B$. The doctor can either give him some pill or send him into surgery. 

Both treatments entail risks and whether the treatment cures the patient or not depends on which disease it had originally.

The causal model that governs this situation is shown in Figure \ref{causal_model}

\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{/Users/MauricioGS1/INAOE/Segundo_Semestre/Seminario/Semana12/codigo/causal_graph.png}}
\caption{Causal graphical model: the target variable is causally influenced by the disease the patient has, the treatment assigned and the survival to the secondary effects of treatment.}
\label{causal_model}
\end{center}
\vskip -0.2in
\end{figure}

The node corresponding to the variable lives is the \textit{target variable} and, in this example, the only variable that can be intervened upon is the treatment.

In this scenario, Nature's move will consist in randomly assigning the disease to the patient. Then, the medic will asign a treatment, the decision nodes for this play form an information set because the medic doesn't know how she arrived there since she doesn't know what disease did Nature assign. Finally, Nature will sample the consequence of the treatment from the causal model and the medic will observe the outcome.

We consider three cases of increasing complexity:
\begin{itemize}
\item The decision maker fully knows the causal model.
\item The decision maker knows only the graph structure.
\item The decision maker knows nothing about the causal model. 
\end{itemize}

\subsection{The casual model is completely known}
If the decision maker knows the causal model, then she can obtain the probabilities of different values for the target variable given that an intervention on \textit{treatment} is made. 

The treatment which achieves the highest probability for the desired value of the target variable will be chosen.

The action thus selected will be a \textit{best response} for the decision maker and the max expected utility choice.

Applying Pearl's \cite{pearl2009causality} do-calculus, we see that the interventional distribution $P_{do(Tr)}(V)$ is given by
\[ \sum_{E,R}P(V|E,Tr,R)P(R|Tr)P(E) \]
\subsection{Only the structure is known}
If only the structure of the graph is known, the decision maker will have \textit{beliefs} over the parameters (conditional probabilities) of the model which she must learn by repetitions.

As usual in the previous case, Nature is considered to play first to asign a random state of the environment, which in this case is the disease.

The decision maker (medic) doesn't know the probabilities, but since she knows the graph structure, she can explicitly a non interventional expression for the invterventional distribution and the values that appear in the expression can be estimated from succesive observations.

\subsection{The model is not known}
The causal model were unknown, the decision maker will have to deal with the problem using only any previous knowledge and his own intuitions. The set of any previous knowledge and considerations will be known as \textit{beliefs}, which will take the form of a probability distributions over causal models. 

\bibliography{/Users/MauricioGS1/INAOE/Segundo_Semestre/Propuesta/Bibliografia.bib}
\bibliographystyle{icml2018}





\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018. It was modified from a version from Dan Roy in
% 2017, which was based on a version from Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.

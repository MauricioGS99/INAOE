% Sample LaTeX file for creating a paper in the Morgan Kaufmannn two
% column, 8 1/2 by 11 inch proceedings format.

\documentclass[letterpaper]{article}
\usepackage{uai2019}
\usepackage[margin=1in]{geometry}
\usepackage{breakcites}
\usepackage{graphicx}
\usepackage{subfigure}
% Set the typeface to Times Roman
\usepackage{times}

\title{Structure Learning for Causal Decision Making}

\author{Anonymous authors.} % LEAVE BLANK FOR ORIGINAL SUBMISSION.
          % UAI  reviewing is double-blind.

% The author names and affiliations should appear only in the accepted paper.
%
%\author{ {\bf Harry Q.~Bovik\thanks{Footnote for author to give an
%alternate address.}} \\
%Computer Science Dept. \\
%Cranberry University\\
%Pittsburgh, PA 15213 \\
%\And
%{\bf Coauthor}  \\
%Affiliation          \\
%Address \\
%\And
%{\bf Coauthor}   \\
%Affiliation \\
%Address    \\
%(if needed)\\
%}

\begin{document}

\maketitle

\begin{abstract}
We consider a Decision Problem under Uncertainty where the uncertain events and the outcomes causally related. It is a well known fact that under rational preferences the maximization of expected utility is the only criteria to be used. We address the problem where the decision maker knows the variables in his environment but does not know the causal relations between them, which includes the variable to be intervened when making a decision. Previous works that have studied decision making in causally-controled environments have left open the case where the causal mechanism which controls the environment is unknown, thus advancing knowledge in this direction. In this paper, we propose to extend such limitation by proposing a local structure learning procedure in terms of belief updating, where the beliefs are probabilities over the events of a variable having causal influence over another one.  We show experimentally that such method is capable of finding the causal links that hold in a true causal model after a series of observations are drawn from such true model. 
\end{abstract}

\section{Introduction}
Decision making under uncertain conditions is a fundamental task for intelligent reasoning and an any-day task for human beings and organizations (\cite{savage1954the}, \cite{danks2014unifying}, \cite{lake2017building}). It is a well known fact that if an agent has \textit{rational preferences} then he must choose according to the Maximum Expected Utility criteria, in which the agent chooses an action by considering both his preferences, which are represented by an utility function, and the probability of occurrence of outcomes: with respect to this point, the agent either knows the probabilities in the environment, or, if he does not, by considering a \textit{subjective} probability measure (\cite{von1944theory}, \cite{savage1954the}, \cite{bernardo2000bayesian}, \cite{gilboa2009decision}). 

The case where the uncertainty component in the decision problem is controlled by a \textit{causal mechanism}, has been previously studied in \cite{joyce1999foundations}, \cite{pearl2009causality}, \cite{lattimoreNIPS2016}, \cite{sen2017identifying}, \cite{gonzalez2018playing}, \cite{2019arXiv190202279G}. In particular, \cite{joyce1999foundations} provided the intuition that a decision maker should consider what is \textit{caused} by his actions, and \cite{pearl2009causality} proposed decision-making by maximizing a function involving the well known \textit{do} operator.

In this work we consider that the causal mechanism controlling the environment is represented as a Causal Graphical Model which is unknown by the agent and assumed to remain fixed and invariant to interventions (\cite{woodward2005making}). In recent papers, such as those by \cite{lattimoreNIPS2016}, \cite{sen2017identifying} and \cite{gonzalez2018playing} it is assumed that the decision maker knows either all of, or a certain aspect such as the structure, of the causal model. Here we attempt to relax such assumption and allowint the decision maker to know only the variables in the model, with the help of an \textit{ordering} in the variables in such a way that it is know which variables can not cause each other. 

\section{On Causality and Learning}
Several definitions of Causality have been attempted by philosophers and scientists, such as those described in \cite{holland1986statistics}. We use here the formal definition of Causality given by \cite{spirtes2000causation}, which belongs to the family of \textit{manipulationist} theories as described by \cite{woodward2005making}. We consider Causal Graphical Models (\cite{koller2009probabilistic}, \cite{sucar2015probabilistic}) as representations of the causal relations that hold in an environment and the resulting interventional distribution.

From the human learning perspective, it has been shown that humans acquire and use causal information for decision-making and that humans even consider their actions as interventions in the world (\cite{hagmayer2009decision}, \cite{wellen2012learning} \cite{hagmayer2013repeated}). It has also been argued that humans tend to ignore probabilistic information and assign more importance to causal information (\cite{tversky1980causal}, \cite{pearl2009causality}). Human beings focus on \textit{local} aspects while learning causal relationswhich are later unified into a single structure (\cite{fernbach2009causal}, \cite{waldmann2008causal},  \cite{danks2014unifying}). Following this idea, \cite{wellen2012learning} propose a model to explain how observations  and interventions are used by human beings to learn causal relations in terms of a local prediction-error learning. Following this line of thought, we propose here a local probabilistic encoding of the uncertainty that a decision maker has over the existence or not of causal relations between variables.

\section{Rationality and Decision Making under}
In this work we begin with a Decision Problem under Uncertainty where an agent, who has rational preferences, faces the problem of choosing one among many available actions with uncertain consequences. From the work of \cite{von1944theory} and \cite{savage1954the}, we know that the only criteria for making choices is the maximization of expected utility with respect to the agent's preferences and a probability distribution which represents either the probabilities of the uncertain events, or the agents own beliefs about such uncertainty. 

Since \cite{joyce1999foundations} it has been argued that a decision maker should consider all of his beliefs about what will his decisions cause, while \cite{pearl2009causality} proposes that a rational agent in the presence of a causal environment should optimize the function $U(x)$ defined as 
\[ U(x)=\sum_y P(y | do(x)) u(y), \]
we notice that this function does not consider the agent's beliefs, or current knowledge, about the causal structure that holds in his environment as opposed to \cite{gonzalez2018playing} and \cite{2019arXiv190202279G} who make use of an implicit probability distribution over causal structures, while Pearl's function assumes a single causal structure. 

\section{Related Work}

In \cite{lattimoreNIPS2016}, the problem of finding a best intervention over a known causal model for a fixed number of learning trials is considered and it was found that by considering causal information a \textit{faster} optimal-action learning can be achieved. Their assumption of knowing the causal model was relaxed by \cite{sen2017identifying} who considers a partially known causal model and allows interventions over a the unknown part of the model. In \cite{gonzalez2018playing} it was proposed that a rational decision maker can find an optimal action by holding \textit{beliefs} about the existence and strength of causal relations and by using those beliefs \textit{as if} they were the true relations in order to make a choice and then updating those beliefs after observing what the chosen action \textit{caused} good actions can be found. Such procedure implicitly considers a distribution over Causal Graphical Models, where each structure is used within each step in otder to make a choice by considering his causal knowledge as it if were true, as proposed by \cite{joyce1999foundations}. Their work assumes that the decision maker knows the structure, but not the associated parameters, of the model. Later, \cite{2019arXiv190202279G}, such authors formalize that procedure by stating a formal criteria which has the form:
\[  a^\ast = \textrm{ argmax }_{a \in \mathcal{A}}\sum_g P(Y=1 | do(a), g)P(g), \]
where $\mathcal{A}$ is the set of available actions to the decision maker and $1$ is the most desired value of the \textit{objective variable} $Y$, for the decision maker. We notice that since the action chosen is the action with the highest probability of causally producing the most desired action, then $a^\ast$ necesarilly is the action that maximizes the expected utility for the agent. The function above described is indeed a counterfactual distribution, since it allows to compare the probability of causing a desired actions by alternative actions that were not chosen.


It remains an open question to tackle the problem of a fully unknown structure. It is known that from observational data alone, a Causal Graphical Model is identifiable up to Markov equivalence without any the assumption of a specific functional model with given error distributions (\cite{hauser2012characterization}, \cite{hauser2012two}, \cite{peters2011identifiability}). We pretend to relax the mentioned limitations to the case of a rational decision maker who knows the variables that control his environment and he has extra knowledge of variables that, in principle can not be cause of each other. 

\section{Structure Learning: a local approach}
We consider the problem of extending the work of \cite{gonzalez2018playing} in the setting of \cite{2019arXiv190202279G}: this is, a $(\mathcal{A}, \mathcal{E}, \mathcal{C}, \mathcal{G}, \succeq)$ where $(\mathcal{A}, \mathcal{E}, \mathcal{C}, \succeq)$ is a classical Decision Problem under Uncertainty as defined in \cite{bernardo2000bayesian} and $\mathcal{G}$ is a Causal Graphical Model (\cite{spirtes2000causation}, \cite{koller2009probabilistic}, \cite{sucar2015probabilistic}) such that the set of available actions $\mathcal{A}$ and the set of outcomes $\mathcal{C}$ are related through the variables of the Causal Model $\mathcal{G}$; i.e., the events in the family $\mathcal{E}$ correspond to variables in $\mathcal{G}$. It is assumed that the agent does not know the Causal Model $\mathcal{G}$, which is equivalent to not knowing the probabilities of the events $E \in \mathcal{E}$. The model $\mathcal{G}$ is also assumed to remain fixed and to be invariant under interventions \cite{woodward2005making} and to satisfy the conditions expressed in \cite{spirtes2000causation} together with Causal Sufficiency. The variable in $\mathcal{G}$ which encodes the consequence of the action taken by the agent will be referred as \textit{target variable} since it is the variable where the agent whishes to obtain a desired result. 

Causal information use and learning when the underlying model is completely unknown is a difficult task (\cite{lattimoreNIPS2016}). We will consider a series of assumptions in order to simplify the problem. We consider:
\begin{enumerate}
\item The decision maker knows the variables in the model, let $V=\{ X_1,...,X_n \}$ be the set of variables.
\item The decision maker knows which variable can he intervene and this variable does not depend on others.
\item The decision maker knows which variable he wants to affect with his interventions. 
\item The decision maker can fully observe realizations of the variables from the true causal model $\mathcal{G}$, but such realizations are independent.
\item Variables are binary-valued $\{0,1 \}$ and interpreted as \textit{acting} on them or not. For example, giving a patient a drug or not. 
\end{enumerate}
The last assumption appears to be a very strong one, but the multi-valued case can be dealt with by replacing the variable with an artificial one which is binary-valued, where one of the states correspond to the values of the original variable, and the other to doing nothing, as in the binary case.

\subsection{The form of uncertainty}
Our approach begins by noticing that if the decision maker does not know the relations between the (known) variables, then his uncertainty about the causal structure has the following \textit{form}: Does $A$ cause $B$? For any pair of variables $A,B$ in V. Since we are following a Bayesian approach, we translate this statement into:
\[p_{AB}=P(A \textrm{ cause } B). \]
Now, the idea is to update $p_{AB}$ according to the manipulationist idea stated in \cite{woodward2005making} where a manipulation in $A$ should translate in a change of value in $B$. Since we are assuming that the variables are binary and interpreted as acting on them or not (consider for example giving a certain treatment or not), the agent will increase his probability of $A$ causing $B$ if the pair $(A=1,B=1)$ is observed. We know from \cite{holland1985statistics} that manipulation is fundamental to the notion of Causality, and although we notice that our decision maker is merely \textit{observing}, we are interpreting the binary-nature of our variables as observing manipulations over them in the form of \textit{acting} or them or not. Since the probability $p_{AB}$ is considered for any pair $(A,B)$ we must be careful in order not to update also $p_{BA}$ since from \cite{spirtes2000causation} we have that if $A$ causes $B$, then $B$ can not cause $A$. We add an extra assumption: the decision maker has a partial ordering $\succeq$ of the variables which corresponds to variables that can not cause each other. This extra assumption, although a strong one, can be thought of expert knowledge in the domain of the decision problem. 

\subsubsection{Uncertainty Updating}
Given that the decision maker can observe a full realization of $X_t=(X_1=x_1,...,X_n=x_n)$ of the variables from the true causal model, where $x_i \in \{0,1 \}$, then for any pair $X_i,X_j$ with $X_j \succeq X_i$, if $(X_i=1, X_j=1)$ is observed on stage $t$, then the belief $p_{X_i X_j}$ is increased by de decision maker to:
\[  p_{X_i X_j}^{(t+1)} = p_{X_i X_j}^{(t)}+\alpha (1-p_{X_i X_j}^{(t)}) \textrm{ for some } \alpha \in (0,1).  \]
On the other hand, if $(X_i=1, X_j=0)$ is observed on stage $t$, then we decrease $p_{X_i X_j}$ to:
\[ p_{X_i X_j}^{(t+1)} =   \alpha p_{X_i X_j}^{(t)}  \textrm{ for some } \alpha \in (0,1). \]
Once the values  $p_{X_i X_j}$ are updated for every $i,j$ such that $X_j \succeq X_i$, the procedure is once again started with a new observation $X_{t+1}$.
\subsubsection{Obtaining a structure and decision making}
After a series of rounds of observation and belief updating it is expected that the information provided by the environment, together with the partial ordering, will allow the decision maker to update his beliefs about the existence of a causal relation between variables in such a way that the stronger (bigger than some threshold) values are considered as a relation existing between a pair of variables. Once a causal structure $\bar{\mathcal{G}}$ is obtained, the decision maker uses this structure \textit{as if} it were the true causal model and then use the procedure described in \cite{gonzalez2018playing} in order to choose an action and observe the causal consequence of the action; this procedure ends with a vector parameters $\alpha$ over the Conditional Probability Tables of the Causal Model which has structure $\bar{\mathcal{G}}$, and such parameters can be used in order to start again the structure-learning procedure, since a low-value parameter points to a possible non-existence of a causal link in $\bar{\mathcal{G}}$ when the outcome of the action is considered.

\section{Experiments and Results}
In order to test our method, we use the simple example in \cite{gonzalez2018playing}, in which a sick patient arrives to a hospital and a medic who does not know his disease must give him some treatment, which can have or not a reaction, which can kill him. The Causal Graphical Model that controls what happens to the patient is shown in Figure \ref{causal_model}.

\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{/Users/MauricioGS1/INAOE/Propuesta/causal_graph.png}}
\caption{The true Causal Graphical Model for the test scenario: the target variable \textit{Lives} is causally influenced by the disease the patient has, the treatment assigned and the survival to the secondary effects of treatment.}
\label{causal_model}
\end{center}
\vskip -0.2in
\end{figure}

We test our method by starting with a random initialization of the probabilities of a variable causing another and updating as mentioned. As an external input we included a list of pairs of variables in which the first element can not cause the second one. Using this list, a second list of \textit{possible causes} was obtained and to the elements of this list random probabilities were assigned. A value of $\alpha=0.8$ was used, and $\alpha$ was decreased by a factor of $1/k$ where $k$ was the current round. After 10 rounds of observing realizations from the true model we see in Figure \ref{Results }that the beliefs about causal relations that do hold in Figure \ref{10_rounds} tend to $1$ while non-existing links go down to $0$ 

\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{/Users/MauricioGS1/INAOE/UAI_2019/Code/results_10_2_ylabel}}
\caption{Beliefs about the existence of causal links between variables.}
\label{10_rounds}
\end{center}
\vskip -0.2in
\end{figure}

\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{/Users/MauricioGS1/INAOE/UAI_2019/Code/results_25_2.png}}
\caption{Beliefs about the existence of causal links between variables in 25 rounds.}
\label{25_rounds}
\end{center}
\vskip -0.2in
\end{figure}

\section{Conclusions and Future Work}
We have proposed a method for finding a causal structure based on the updating of beliefs by a rational agent about the existence of causal relations between variables. The need of a causal ordering is required since it is known that based on mere observations a Directed Graph can not be obtained. Our method allows the use of a previously shown method for decision making based on causal information in the case where the decision maker only knows the variables of the model. In a simple case, we tested our method and it was shown experimentally that the proposed method could find the causal links that hold in the true causal model, while gradually stop believing in the existence of links not present in the true causal model.

There are still several issues that must be adressed in the near future, such as the case of multi-valued variables or considering a dynamically changing causal model. Also, the generale case involving variable discovery must be solved in order to solve the problem of causal decision making when an unknown causal mechanism controls the environment. 

\newpage
\subsubsection*{Acknowledgements}
The authors would like to thank \texttt{<Anonymous>} for valuable comments and insights. 

\bibliographystyle{apalike}
\bibliography{/Users/MauricioGS1/INAOE/Propuesta/Bibliografia.bib}

\end{document}